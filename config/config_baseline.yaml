#seed - SAME BETWEEN RUNS
seed: 1234

#data - SAME BETWEEN RUNS
dataset_dir: "../Datasets/ILSVRC/Data/CLS-LOC/"
dataset: "Imagenet-100"
num_classes: 100
subset_file_name: "imagenet100.txt"

#distributed training - SAME BETWEEN RUNS
num_nodes: 1
gpus: 4
workers: 12
distributed_backend: "ddp"

###############################################

#Experiment Stuff - CHANGE BETWEEN RUNS
experiment_name: "TEST_Rand50"

#Distortions and parameters - CHANGE BETWEEN RUNS
distortion: "randommask" #randommask or squaremask
percent_missing: 0.5 #only for randommask -THIS IS A FLOAT, PUT IN E.G. 0.9 FOR () percent missing
#length: 100 #Only for squaremask
#std: None #only for Gaussian noise
#kernel_size: None #Only for Gaussian Blur
#sigma: None #Only for Gaussian Blur

#model - CHANGE BETWEEN RUNS
encoder: "resnet" #'clip' or 'resnet'
resnet_model: "50" #50 or 101
clip_model: None #'ViT-B/32' or 'RN50' , only matters if encoder: "clip"
pretrained: True

#training
max_epochs: 3
lr: 0.001
batch_size: 100 #150 for clip resnet, 300 for clip Vit, 100 for resnet

#logging
log_save_interval: 1 #set this to be equal to num_epochs if row_log_interval is 1
row_log_interval: 1  

#validation
check_val_every_n_epoch: 1 
