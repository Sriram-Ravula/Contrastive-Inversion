#seed - SAME BETWEEN RUNS
seed: 1234

#data - SAME BETWEEN RUNS
dataset_dir: "/tmp/ImageNet100/"
dataset: "ImageNet100"
num_classes: 100

#distributed training - SAME BETWEEN RUNS
num_nodes: 1
gpus: 4
workers: 12
distributed_backend: "ddp"

###############################################

#Experiment Stuff - CHANGE BETWEEN RUNS
experiment_name: "CLIP_RN101_RAND90_50"

#Distortions and parameters - CHANGE BETWEEN RUNS
distortion: "randommask" #randommask or squaremask
percent_missing: 0.9 #only for randommask -THIS IS A FLOAT, PUT IN E.G. 0.9 FOR () percent missing
fixed_mask: False

#model - CHANGE BETWEEN RUNS
encoder: "clip" #'clip' or 'resnet'
#resnet_model: "101" #50 or 101
clip_model: 'RN101' #'ViT-B/32' or 'RN50' or "RN101" or "RN50x4", only matters if encoder: "clip"
freeze_backbone: False

#training
max_epochs: 50
lr: 0.001
batch_size: 64 #100 for clip RN50, 150 for clip Vit, 64 for clip RN101,      

#logging
log_save_interval: 1 #set this to be equal to num_epochs if row_log_interval is 1
row_log_interval: 1  
logdir: "/tmp/Logs"

#validation
check_val_every_n_epoch: 1
