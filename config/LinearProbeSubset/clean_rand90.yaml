#seed - SAME BETWEEN RUNS
seed: 1234

#data - SAME BETWEEN RUNS
dataset_dir: "/tmp/imagenet100/"
dataset: "ImageNet100"
num_classes: 100
emb_dim: 512

#distributed training - SAME BETWEEN RUNS
num_nodes: 1
gpus: 4
workers: 12
distributed_backend: "ddp"

###############################################

#Experiment Stuff - CHANGE BETWEEN RUNS
experiment_name: "clean_rand90"
checkpoint_path: None

#Distortions and parameters - CHANGE BETWEEN RUNS
distortion: "randommask" #randommask or squaremask
percent_missing: 0.9 #only for randommask -THIS IS A FLOAT, PUT IN E.G. 0.9 FOR () percent missing
fixed_mask: False

encoder: "clean"

#training
max_epochs: 10
lr: 0.001
batch_size: 128 #100 for clip RN50, 150 for clip Vit, 64 for clip RN101,
use_subset: False

#logging
log_save_interval: 10 #set this to be equal to num_epochs if row_log_interval is 1
row_log_interval: 1
logdir: "/tmp/Logs"

#validation
check_val_every_n_epoch: 1
